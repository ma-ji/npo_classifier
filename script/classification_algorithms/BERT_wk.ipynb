{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HcxdG61s-_qa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rqp5p_ra-_qj"
   },
   "source": [
    "### Test the loaded models and tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FHKbyGO6Qbtd",
    "outputId": "2d53d3cf-fb8a-4374-b58d-bc756422e3eb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "train_path = '../dataset/UCF/train/'\n",
    "test_path = '../dataset/UCF/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrrTWzGM-_qm"
   },
   "source": [
    "#### Load UCF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m6wurxc-_qm"
   },
   "outputs": [],
   "source": [
    "broad_cat_dict={'I': ['A'],\n",
    "                'II': ['B'],\n",
    "                'III': ['C', 'D'],\n",
    "                'IV': ['E', 'F', 'G', 'H'],\n",
    "                'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n",
    "                'VI': ['Q'],\n",
    "                'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n",
    "                'VIII': ['X'],\n",
    "                'IX': ['Y'],\n",
    "                'X': ['Z'],\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYBS25xFrmLk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_dataset(data_path):\n",
    "  file_list=os.listdir(data_path)\n",
    "  df_data=pd.DataFrame()\n",
    "  for file in file_list:\n",
    "    print(data_path+file)\n",
    "    df_data=pd.concat([df_data, pd.read_pickle(data_path+file, compression='gzip')])\n",
    "\n",
    "  df_data['mission_prgrm_spellchk']=df_data['TAXPAYER_NAME']+' '+df_data['mission_spellchk']+' '+df_data['prgrm_dsc_spellchk'] # Using spell-checked.\n",
    "  df_data['broad_cat']=df_data['NTEE1'].apply(ntee2cat)\n",
    "  print(len(df_data['mission_prgrm_spellchk']), len(df_data['NTEE1'].drop_duplicates()), len(df_data['broad_cat'].drop_duplicates()))\n",
    "  return df_data\n",
    "\n",
    "def ntee2cat(string):\n",
    "  return [s for s in broad_cat_dict.keys() if string in broad_cat_dict[s]][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "M72qqJPFn4Sf",
    "outputId": "5211e61e-8994-4f5a-b984-a800503345bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/UCF/train/df_ucf_train.pkl.gz_4of4\n",
      "../dataset/UCF/train/df_ucf_train.pkl.gz_0of4\n",
      "../dataset/UCF/train/df_ucf_train.pkl.gz_3of4\n",
      "../dataset/UCF/train/df_ucf_train.pkl.gz_2of4\n",
      "../dataset/UCF/train/df_ucf_train.pkl.gz_1of4\n",
      "154424 25 9\n"
     ]
    }
   ],
   "source": [
    "df_train = split_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_kVw1LCQjWnb",
    "outputId": "fafa92f7-e0f4-4304-8be5-6117900c8ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/UCF/test/df_ucf_test.pkl.gz\n",
      "38607 25 9\n"
     ]
    }
   ],
   "source": [
    "df_test = split_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "CFuqOIdKZ1o1",
    "outputId": "4ce83ff8-a8f0-4ce5-c242-292ddc3401a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /root/anaconda3/lib/python3.7/site-packages (2.6.0)\n",
      "Requirement already satisfied: requests in /root/anaconda3/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sentencepiece in /root/anaconda3/lib/python3.7/site-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: boto3 in /root/anaconda3/lib/python3.7/site-packages (from transformers) (1.12.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/anaconda3/lib/python3.7/site-packages (from transformers) (4.43.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/anaconda3/lib/python3.7/site-packages (from transformers) (2020.2.20)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /root/anaconda3/lib/python3.7/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: numpy in /root/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /root/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.38)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /root/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /root/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /root/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.12 in /root/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (1.15.12)\n",
      "Requirement already satisfied: six in /root/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: joblib in /root/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /root/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /root/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.12->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /root/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.12->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaUGh5wF-_qs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkMeZSx0-_qw"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#encoding function\n",
    "def padding_text(dataset):\n",
    "  input_ids=[]\n",
    "  attention_masks=[]\n",
    "  text_list =  dataset['mission_prgrm_spellchk']\n",
    "  for text in text_list:\n",
    "    encode_plus = tokenizer.encode_plus(            \n",
    "                        text,    \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 512,        \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt')   \n",
    "    input_ids.append(encode_plus['input_ids'])\n",
    "    attention_masks.append(encode_plus['attention_mask'])\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "  lb_broad_cat = preprocessing.LabelEncoder().fit_transform(dataset['broad_cat'])\n",
    "  lb_major_group = preprocessing.LabelEncoder().fit_transform(dataset['NTEE1'])\n",
    "  lb_broad_cat = torch.tensor(lb_broad_cat)\n",
    "  lb_major_group = torch.tensor(lb_major_group)\n",
    "  return input_ids, attention_masks, lb_broad_cat, lb_major_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76dyknRG-_q0"
   },
   "outputs": [],
   "source": [
    "#encoding train and test dataset\n",
    "input_ids_train, attention_masks_train, lb_broad_group_train, lb_major_group_train = padding_text(df_train)\n",
    "input_ids_test, attention_masks_test, lb_broad_cat_test, lb_major_group_test = padding_text(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZne6VF9-_q4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import *\n",
    "\n",
    "#combining data and loading Bert\n",
    "def train_test_dataset(train_label, test_label, num_label, batch_size):\n",
    "  \n",
    "  train_dataset = TensorDataset(input_ids_train, attention_masks_train, train_label)\n",
    "  test_dataset = TensorDataset(input_ids_test, attention_masks_test, test_label)\n",
    "  \n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset),\n",
    "              batch_size = batch_size )\n",
    "\n",
    "  validation_dataloader = DataLoader(test_dataset,\n",
    "              sampler = SequentialSampler(test_dataset), \n",
    "              batch_size = batch_size)\n",
    "  \n",
    "  global model\n",
    "\n",
    "  model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                                num_labels=num_label) \n",
    "  model.cuda()\n",
    "  \n",
    "  \n",
    "  return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0Hjw1ZwZiXK"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "#function for adjusting parameters\n",
    "def parameters(learning_rate, eps, num_epoch):\n",
    "  \n",
    "  global epochs\n",
    "  epochs = num_epoch\n",
    "  optimizer = AdamW(model.parameters(),\n",
    "                    lr = learning_rate, \n",
    "                    eps = eps \n",
    "                  )\n",
    "  \n",
    "  total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                              num_warmup_steps = 0, \n",
    "                                              num_training_steps = total_steps)\n",
    "  return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBCrvwtZZl30"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#function that will evaluate the accuracy of the model\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L45ZQt-ZZqAR"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtewSfztZvA7"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#loading data into the Bert model\n",
    "\n",
    "def run_bert(train_dataloader, validation_dataloader, optimizer, scheduler):\n",
    "\n",
    "  seed = 42\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed) \n",
    "\n",
    "  loss_values = []\n",
    "\n",
    "  for epoch_i in range(0, epochs):\n",
    "\n",
    "      print(\"\")\n",
    "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "      print('Training...')\n",
    "\n",
    "      t0 = time.time()\n",
    "\n",
    "      total_loss = 0\n",
    "\n",
    "      \n",
    "      model.train()\n",
    "      model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    \n",
    "      for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "          if step % 2000 == 0 and not step == 0:\n",
    "              elapsed = format_time(time.time() - t0)\n",
    "              \n",
    "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "          b_input_ids = batch[0].to(device)\n",
    "          b_input_mask = batch[1].to(device)\n",
    "          b_labels = batch[2].to(device)\n",
    "          \n",
    "          model.zero_grad() \n",
    "          \n",
    "          outputs = model(b_input_ids, \n",
    "                      token_type_ids=None, \n",
    "                      attention_mask=b_input_mask, \n",
    "                      labels=b_labels)\n",
    "          \n",
    "          loss = outputs[0] \n",
    "          total_loss += loss.item()\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "          \n",
    "          optimizer.step()\n",
    "\n",
    "          scheduler.step()\n",
    "\n",
    "      avg_train_loss = total_loss / len(train_dataloader)            \n",
    "      \n",
    "      loss_values.append(avg_train_loss)\n",
    "\n",
    "      print(\"\")\n",
    "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "      print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "          \n",
    "      #               Validation\n",
    "\n",
    "      print(\"\\n\")\n",
    "      print(\"Validation...\")\n",
    "\n",
    "      t0 = time.time()\n",
    "\n",
    "      model.eval()\n",
    "\n",
    "      eval_loss, eval_accuracy = 0, 0\n",
    "      nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "      for batch in validation_dataloader:\n",
    "          \n",
    "          batch = tuple(t.to(device) for t in batch)\n",
    "          \n",
    "          b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "          with torch.no_grad():        \n",
    "\n",
    "      \n",
    "              outputs = model(b_input_ids, \n",
    "                              token_type_ids=None, \n",
    "                              attention_mask=b_input_mask)\n",
    "          logits = outputs[0]\n",
    "\n",
    "          logits = logits.detach().cpu().numpy()\n",
    "          label_ids = b_labels.to('cpu').numpy()\n",
    "          \n",
    "          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "          \n",
    "          eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "          nb_eval_steps += 1\n",
    "\n",
    "      # Report the final accuracy for this validation run.\n",
    "      print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "      print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "  print(\"\")\n",
    "  print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "002213350b614726ae550decff970d5e",
      "e87c0ed162f546ab8f19650870a5fee7",
      "165e1bbce2274f2aa86059ec00a09628",
      "b393796083f341a587d2495b972bf575",
      "26446f80406e436797833424bd581ee1",
      "94e818de175e49fcb63da727847ac49c",
      "55db93bae33b4b728db84f3ef192866a",
      "7d3dcbddee5c4e3fbbb0c97da0bb7b8c",
      "9839ff2b08ab42d5aceef7fea0946c6a",
      "795b00e6d8964bc6b1ae8e7dcd9d9e7f",
      "6b3e018c7ed74f1197065e4585409329",
      "f1e946af14b6447c9a0c45013a145520",
      "96d4373c206a4cbfab78763149d85df9",
      "5d13ba2bf676487f939fa0f120f1b1dc",
      "e521ff2147f745e1b55724f51e5e029d",
      "afc2cd4f389c415b9404a8ec2e4d7a57"
     ]
    },
    "colab_type": "code",
    "id": "Q0bASJDsrAj0",
    "outputId": "31be0ac7-5746-4590-e16c-99328d456101"
   },
   "outputs": [],
   "source": [
    "#load broad group label\n",
    "train_dataloader, validation_dataloader= train_test_dataset(train_label = lb_major_group_train, \n",
    "                                                            test_label = lb_major_group_test, \n",
    "                                                            num_label = 25, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "7nICEZ-3wsSV",
    "outputId": "942261b8-c6dd-4674-995a-584503fb5145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:38.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:19:12.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:47.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:23.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:47:52.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:22.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:06:52.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:23.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:25:53.\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 1:32:05\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:36.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:19:07.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:38.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:10.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:47:48.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:28.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:07:02.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:32.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:26:03.\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 1:32:15\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:30.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:19:01.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:33.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:02.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:47:34.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:05.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:06:36.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:06.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:25:35.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 1:31:45\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:39.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:19:18.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:57.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:37.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:48:11.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:43.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:07:13.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:42.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:26:16.\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 1:32:27\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "optimizer, scheduler = parameters(learning_rate = 5e-5, eps = 1e-12, num_epoch = 4)\n",
    "run_bert(train_dataloader, validation_dataloader, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZNK8tPTtTih"
   },
   "outputs": [],
   "source": [
    "#load broad group label\n",
    "train_dataloader, validation_dataloader= train_test_dataset(train_label = lb_broad_group_train, test_label = lb_broad_cat_test, num_label = 9, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "colab_type": "code",
    "id": "07xSPOUvw49R",
    "outputId": "6934973a-1f1d-4bd8-efe5-714126bf3044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:30.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:19:13.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:43.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:20.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:47:57.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:35.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:07:08.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:44.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:26:25.\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 1:32:44\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.89\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:30.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:18:59.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:32.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:12.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:47:44.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:17.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:06:47.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:16.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:25:44.\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 1:31:55\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:07:22\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:28.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:19:01.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:41.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:13.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:47:44.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:13.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:06:42.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:10.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:25:44.\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 1:32:02\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:07:22\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch 2,000  of  19,303.    Elapsed: 0:09:34.\n",
      "  Batch 4,000  of  19,303.    Elapsed: 0:19:04.\n",
      "  Batch 6,000  of  19,303.    Elapsed: 0:28:38.\n",
      "  Batch 8,000  of  19,303.    Elapsed: 0:38:11.\n",
      "  Batch 10,000  of  19,303.    Elapsed: 0:47:47.\n",
      "  Batch 12,000  of  19,303.    Elapsed: 0:57:17.\n",
      "  Batch 14,000  of  19,303.    Elapsed: 1:06:45.\n",
      "  Batch 16,000  of  19,303.    Elapsed: 1:16:14.\n",
      "  Batch 18,000  of  19,303.    Elapsed: 1:25:43.\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 1:31:53\n",
      "\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "optimizer, scheduler = parameters(learning_rate = 5e-5, eps = 1e-12, num_epoch = 4)\n",
    "run_bert(train_dataloader, validation_dataloader, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HhuGYQ2-_rf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "New Npoclass Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "002213350b614726ae550decff970d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_165e1bbce2274f2aa86059ec00a09628",
       "IPY_MODEL_b393796083f341a587d2495b972bf575"
      ],
      "layout": "IPY_MODEL_e87c0ed162f546ab8f19650870a5fee7"
     }
    },
    "165e1bbce2274f2aa86059ec00a09628": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94e818de175e49fcb63da727847ac49c",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26446f80406e436797833424bd581ee1",
      "value": 361
     }
    },
    "26446f80406e436797833424bd581ee1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "55db93bae33b4b728db84f3ef192866a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d13ba2bf676487f939fa0f120f1b1dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b3e018c7ed74f1197065e4585409329": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d13ba2bf676487f939fa0f120f1b1dc",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_96d4373c206a4cbfab78763149d85df9",
      "value": 440473133
     }
    },
    "795b00e6d8964bc6b1ae8e7dcd9d9e7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d3dcbddee5c4e3fbbb0c97da0bb7b8c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94e818de175e49fcb63da727847ac49c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d4373c206a4cbfab78763149d85df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9839ff2b08ab42d5aceef7fea0946c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b3e018c7ed74f1197065e4585409329",
       "IPY_MODEL_f1e946af14b6447c9a0c45013a145520"
      ],
      "layout": "IPY_MODEL_795b00e6d8964bc6b1ae8e7dcd9d9e7f"
     }
    },
    "afc2cd4f389c415b9404a8ec2e4d7a57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b393796083f341a587d2495b972bf575": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d3dcbddee5c4e3fbbb0c97da0bb7b8c",
      "placeholder": "​",
      "style": "IPY_MODEL_55db93bae33b4b728db84f3ef192866a",
      "value": " 361/361 [00:13&lt;00:00, 26.2B/s]"
     }
    },
    "e521ff2147f745e1b55724f51e5e029d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e87c0ed162f546ab8f19650870a5fee7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1e946af14b6447c9a0c45013a145520": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afc2cd4f389c415b9404a8ec2e4d7a57",
      "placeholder": "​",
      "style": "IPY_MODEL_e521ff2147f745e1b55724f51e5e029d",
      "value": " 440M/440M [00:11&lt;00:00, 39.5MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
